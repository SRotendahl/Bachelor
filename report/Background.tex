\section{Background}
\subsection{Futhark}
A common way to increase computer performance, is to increase the capacity for parallelism. For practical usage, however, this is difficult to implement, due to low-level GPU-specific languages requiring domain specific knowledge to make full use of that capacity. A wast amount of work has gone into transforming high-level hardware-agnostic code into these low-level GPU-specific languages \cite{inc-flat}. 

The programming language \textbf{Futhark} aims to solve this problem. The creator of Futhark writes the purpose, of the language, nicely on the home page for the language \textit{"Because it’s nicer than writing CUDA or OpenCL by hand!"} \cite{futhark-home}. On the same page, Futhark is described, more precisely, as \textit{"a statically typed, data-parallel, and purely functional array language"}, but better than a description, is an example:
\begin{figure}[H]
\centering
\lstset{language=haskell}
\begin{lstlisting}
let dotprod [n] (xs: [n]f32) (ys: [n]f32): f32 =
	reduce (+) 0f32 (map2 (*) xs ys)

let main [n][m][p] (xss: [n][m]f32) (yss: [m][p]f32): [n][p]f32 =
	map (\xs -> map (dotprod xs) (transpose yss)) xss
\end{lstlisting}%
\caption{Matrix-matrix multiplication in Futhark \cite{ppopp}}
\label{matmultFuthark}
\end{figure}
\noindent A Futhark program for matrix-matrix multiplication can be seen in figure \ref{matmultFuthark}, the syntax is similar to languages such as ML, and Haskell. It is a good example of how Futhark differs from CUDA or OpenCL (we would have liked to include an example of CUDA, but it was to long, so see \ref{cuda-matmult} for that). It allows the programmer to write efficient parallel code, without all the domain specific knowledge regarding massively parallel systems. 

\subsection{Flattening}
%It is difficult to exploit nested data-parallelism. A common approach is to add data-parallel operations, such as \texttt{map}, to existing languages, for example High Performance Fortran. However, this approach is not well suited for irregular data structures, such as trees or graphs \cite{nesl}.
It is difficult to exploit nested data-parallelism. An approach to this problem is flattening \cite{flat}. The aim is to transform nested parallelism, into one-level parallelism. To briefly understand the concept of flattening, we will flatten a nested collection; let \texttt{A = [1, 2, 3, 4, 5, 6]}, this can be flattened into what is called a \textbf{field} \cite{flat}, here represented as a tuple, but it could be a different data-structure. The first element, of the field, is a collection representing the length of the segments, and the second is either a collection, or another field, giving; \texttt{field = (shape, val)}. The collection \texttt{A}, flattened into a field, would be \texttt{(Ashape = [6], Aval = [1, 2, 3, 4, 5, 6])}. This technique can be applied recursively to any depth. A depth of \texttt{n} would give \texttt{n} shape collections, for example let \texttt{B = [[1, 2], [3, 4, 5], [6]]}, this would be flattened to the field \texttt{B = ([3], (Bshape, Bval)) $\to$ B = ([3], ([2, 3, 1], [1, 2, 3, 4, 5, 6]))}. 

With the collection flattened to a field structure, work can now be applied in parallel, by stepping up or down in the field, for example taking the head of each nested collection would step down in \texttt{B} once, to get \texttt{step-down([3], ([3], ([2, 3, 1], [1, 2, 3, 4, 5, 6]))) = ([2, 3, 1], [1, 2, 3, 4, 5, 6])}, and then distributing the head function to each segment in parallel, by giving each segment of \texttt{[1..6]} to a core and performing the function, giving back the field \texttt{([3], [1, 3, 6])}.\\\\
With the ability to flatten, nested parallelism can be mapped to hardware. However this is not necessarily optimal.   
%We could possibly expand on this

\subsection{Incremental flattening}
A principal critical for this code transformation from low-level GPU languages to Futhark, is flattening. 


\begin{comment}
\subsection{Threshold parameters}
To choose the proper code version for the program, based on representative data, we need something to base our choices from. At runtime, Futhark generates some parameters we can use as this basis. These parameters represent a piece of codefi

\subsection{Structure of the threshold parameter}
% Vi har nok skrevet det med dependencies før, men så kan vi bare lige rykke det/flette sammen
The aforementioned threshold parameters, can be dependent on each other. Imagine a nested loop where it is determined, for the outer loop, that it should not be executed in parallel, therefore the inner loop should also not be executed in parallel, thereby making the inner dependent on the outer. These dependencies builds a tree, which an example of can be seen in figure \ref{LocVolCalibTree}.
\begin{figure}[H]
\centering
\input{Tree}
\caption{The dependencies between thresholds, of the test program \texttt{LocVolCalib.fut}. The dependency is based on a comparison of the threshold (T), the edge to the next node is then taken based on that comparison. Each path through the tree, to one, or more, end nodes, is then an execution of the program.}
\label{LocVolCalibTree}
\end{figure}
\noindent To tune a program we need to examine each execution path. It is important not to get an end node confused with an execution path. Two example of paths through the tree in figure \ref{LocVolCalibTree}, that show this, could be;
\begin{itemize}
\item \texttt{\{(T4, False), (T5, False), (T6, False), (T7, True)\}}
\item \texttt{\{(T4, False), (T5, False), (T6, False), (T7, False), (T8, False), (T9, True), (T16, False), (T17, True)\}}
\end{itemize} 
The first path is simple, the code represented by \texttt{T4, T5, T6} is executed in parallel, where everything after it, is executed sequentially. The second path is more interesting, \texttt{T7} has two child nodes, that are reached with a false comparison. Here it is clear that two end nodes is reached, namely \texttt{(E6, E9)}. This is also important to note, because we could have a forest, instead of a single tree, and this would leave multiple end nodes.
\end{comment}

