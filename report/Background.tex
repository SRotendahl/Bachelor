\section{Background}
\subsection{Futhark}
A common way to increase computer performance, is to increase the capacity for parallelism. For practical usage, however, this is difficult to implement, due to low-level GPU-specific languages requiring domain specific knowledge to make full use of that capacity. A wast amount of work has gone into transforming high-level hardware-agnostic code into these low-level GPU-specific languages \cite{inc-flat}. 

The programming language \textbf{Futhark} aims to solve this problem. The creator of Futhark writes the purpose, of the language, nicely on the home page for the language \textit{"Because it’s nicer than writing CUDA or OpenCL by hand!"} \cite{futhark-home}. On the same page, Futhark is described, more precisely, as \textit{"a statically typed, data-parallel, and purely functional array language"}, but better than a description, is an example:
\begin{figure}[H]
\centering
\lstset{language=haskell}
\begin{lstlisting}
let dotprod [n] (xs: [n]f32) (ys: [n]f32): f32 =
	reduce (+) 0f32 (map2 (*) xs ys)

let main [n][m][p] (xss: [n][m]f32) (yss: [m][p]f32): [n][p]f32 =
	map (\xs -> map (dotprod xs) (transpose yss)) xss
\end{lstlisting}%
\caption{Matrix-matrix multiplication in Futhark \cite{ppopp}}
\label{matmultFuthark}
\end{figure}
\noindent A Futhark program for matrix-matrix multiplication can be seen in figure \ref{matmultFuthark}, the syntax is similar to languages such as ML, and Haskell. It is a good example of how Futhark differs from CUDA or OpenCL (we would have liked to include an example of CUDA, but it was to long, so see \ref{cuda-matmult} for that). It allows the programmer to write efficient parallel code, without all the domain specific knowledge regarding massively parallel systems. 

\subsection{Flattening}
%It is difficult to exploit nested data-parallelism. A common approach is to add data-parallel operations, such as \texttt{map}, to existing languages, for example High Performance Fortran. However, this approach is not well suited for irregular data structures, such as trees or graphs \cite{nesl}.
It is difficult to exploit nested data-parallelism. An approach to this problem is flattening \cite{flat}. The aim is to transform nested parallelism, into one-level parallelism

\subsection{Incremental flattening}
A principal critical for this code transformation from low-level GPU languages to Futhark, is flattening. 
 
\begin{multicols}{3}
\begin{itemize}
\item 12
\item 32
\item 23
\end{itemize}
\end{multicols}
\begin{comment}
\subsection{Threshold parameters}
To choose the proper code version for the program, based on representative data, we need something to base our choices from. At runtime, Futhark generates some parameters we can use as this basis. These parameters represent a piece of codefi

\subsection{Structure of the threshold parameter}
% Vi har nok skrevet det med dependencies før, men så kan vi bare lige rykke det/flette sammen
The aforementioned threshold parameters, can be dependent on each other. Imagine a nested loop where it is determined, for the outer loop, that it should not be executed in parallel, therefore the inner loop should also not be executed in parallel, thereby making the inner dependent on the outer. These dependencies builds a tree, which an example of can be seen in figure \ref{LocVolCalibTree}.
\begin{figure}[H]
\centering
\input{Tree}
\caption{The dependencies between thresholds, of the test program \texttt{LocVolCalib.fut}. The dependency is based on a comparison of the threshold (T), the edge to the next node is then taken based on that comparison. Each path through the tree, to one, or more, end nodes, is then an execution of the program.}
\label{LocVolCalibTree}
\end{figure}
\noindent To tune a program we need to examine each execution path. It is important not to get an end node confused with an execution path. Two example of paths through the tree in figure \ref{LocVolCalibTree}, that show this, could be;
\begin{itemize}
\item \texttt{\{(T4, False), (T5, False), (T6, False), (T7, True)\}}
\item \texttt{\{(T4, False), (T5, False), (T6, False), (T7, False), (T8, False), (T9, True), (T16, False), (T17, True)\}}
\end{itemize} 
The first path is simple, the code represented by \texttt{T4, T5, T6} is executed in parallel, where everything after it, is executed sequentially. The second path is more interesting, \texttt{T7} has two child nodes, that are reached with a false comparison. Here it is clear that two end nodes is reached, namely \texttt{(E6, E9)}. This is also important to note, because we could have a forest, instead of a single tree, and this would leave multiple end nodes.
\end{comment}

