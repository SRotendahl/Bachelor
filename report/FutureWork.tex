\section{Reflections \& Future work (Very unfinished)}

Our autotuner does what it's supposed to, performs and exhaustive search of all
possible combinations of code versions in the given datasets and returns the
one that performs the best. This means that in most cases the results it gives
are better than the current autotuner. The problem it has is that to perform an
exhaustive search the number of combinations that needs to be checked increases
very quickly as you add more datasets. In the \texttt{LocVolCalib} program the
number of combinations that needs to be checked for one dataset is 13, while
the number of combinations that needs to be checked if you want to tune for all
three datasets is 5463. 

\begin{itemize}
	\item \textbf{Further filtration} should be performed. There are heuristics
    about Futhark programs, that can be used to reduces the number, a specific
    one is nest of two \texttt{map}s. It is often that we want to work on
    nested data, like a matrix, and mapping over its columns and rows. For this
    we would use two \texttt{map}s, and very rarely is only the outer
    \texttt{map} executed in parallel. However our autotuner does not take such
    heuristics into account (otherwise it would not be an exhaustive search),
    but if heuristics such as these are implemented, the number of thresholds
    for \texttt{map-map} would be reduced exponentially with the number of
    datasets.
	\item \textbf{Synthetic data} is currently being considered, instead of the
    training data we have been using now. The aim is to create data, that can
    emulated the actual data being used, more efficiently. If such synthetic
    data could reduce the number of datasets needed, the number of executions
    that needs to be tested, would be reduced exponentially.	
\end{itemize}

