\section{Introduction}
GPGPU (General-purpose computing on graphics processing units) have been on the
rise, due to limitations on CPUs, such as power consumption, and the fact
that the computational potential of GPUs (Graphical processing unit) is vastly
superior to CPUs, as seen in Figure \ref{potential}. There are technical and physical
issue in reaching this potential, for example memory bandwidth bottle-necking computation, but there is
also the conceptual issue of how to map parallelism to parallel hardware.
\begin{figure}[h]
	\centering
	\includegraphics[width=.8\textwidth]{resources/graf.png}
	\caption{A graph showing the computational potential of CPUs and GPUs from 2000---2016 \cite{cpu-vs-gpu}}
	\label{potential}
\end{figure}

In this project we will implement an autotuner for the programming language
Futhark \cite{futhark-home}. Futhark is a statically typed, data-parallel, and
purely functional array language. The aim of Futhark is to shift the burden of
writing efficient parallel code from the programmer to the compiler. The
burden referred to is the requirement for a deep understanding of GPU hardware architecture and compiler knowledge for the language used, which is necessary to write efficient GPU code. Even when this requirements is met, using common GPU languages such as CUDA and OpenCL will still result in non-portable code as a lot of the optimizations made
are specific to a certain GPU, or at least to a certain GPU architecture. 

\begin{figure}
\centering
\lstset{language=haskell}
\begin{lstlisting}
let dotprod [n] (xs: [n]f32) (ys: [n]f32): f32 =
reduce (+) 0f32 (map2 (*) xs ys)

let main [n][m][p] (xss: [n][m]f32) (yss: [m][p]f32): [n][p]f32 =
map (\xs -> map (dotprod xs) (transpose yss)) xss
\end{lstlisting}%
\captionof{lstlisting}{Matrix-matrix multiplication in Futhark \cite{ppopp}}
\label{IntromatmultFuthark}
\end{figure}
A Futhark program for matrix-matrix multiplication can be seen in listing
\ref{IntromatmultFuthark}. The syntax is similar to languages such as ML and
Haskell. It is a good example of how Futhark differs from CUDA or OpenCL (we
would have included an example of CUDA, but it was too long, it can be found in Appendix
\ref{cuda-matmult}). It should be clear why, if Futhark has the possibility to achieve speeds similar to those of CUDA and OpenCL Futhark would be very preferable.


To achieve the shift in burden from programmer to compiler, the Futhark compiler creates multiple semantically
equivalent versions of the code in a program, where each code version will
exploit a different amount of parallelism. These code versions can represent the entire program, while some versions needs to be combined with others in order to represent the entire program. The code versions are then to be
discriminated at runtime and to do so, Futhark assesses
the amount of parallelism contained in each function of the program, based on the
data being worked on. Put simply, if you have a matrix (\texttt{A}) of size $m
\times n$, and you execute a function (\texttt{inc}) incrementing each element,
then the parallel amount of \texttt{inc A} would be $m \times n$. Along with
these code versions, Futhark generates predicates that guard the code versions.
The aim is then to give a Futhark program parameters at runtime, and using the
guards, the knowledge of the hardware being execute on, along with the data
being worked on, it will select the best execution.

Adjusting these parameters to select the execution that will minimize the
running time is called tuning. The aim of this project is to automatize this
process, so that it does not have to be done by hand. This process is what we
call autotuning.

An analogy to tuning Futhark, is being a kid in a candy store. We have a bag
(parallel hardware, which will most commonly be a GPU), that is to be filled
with candy (parallelism in a program). We do not have a favorite type of candy
(the code versions being semantically equivalent), so we want to want to
efficiently pack the bag in order to get as much candy as possible. If we
overpack the bag, it will get to heavy (introducing overhead larger than gain)
and it will take longer to get the bag home, and if we underfill it, we will
obviously get less candy. Therefore we need to put a piece of candy in the bag
(a parallel function in the program), and then asses the next candy pieces
size, and the remaining capacity of the bag, and if the candy fits we put it in
(tuning the parameters). 
