\section{Search space and portability}
%13
There are two main reasons for the use of autotuning (compared to manual tuning), the search space of different threshold settings, and the portability of the code.
\paragraph{The search space} for thresholds is quite large. The threshold parameters has a value of $2^{15}$ as a default, lets us then consider matrix-matrix multiplication again (Figure \ref{MatMultTreeFilled}). Here we have 4 thresholds, which would leave $(2^{15})^4 \approx 1.153\times10^{18}$ different threshold parameter settings (and this is assuming that $2^{15}$ is an appropriate maximum value for all hardware, which is not the case). However we see that a setting can only end in five different executions. This is due to a data value of $128$ would result in the same in all the settings from $2^{15}$ down $128$. So to manually tune the search space is incredible tedious and repetitive.
\paragraph{Portability} of code is important, especially for GPU's due to the low level link between the code and the architecture (GPU threads, blocks/groups etc.). When tuning we tune to specific hardware, and representative datasets, so as soon as the code is to be executed on a different system (with a potentially different size of input data), the tuning performed would be useless (and in the worst case even detrimental to performance).\\

To illustrate the problem of repetitiveness through the search space we see Figure \ref{MatMultTreeFilled}, with the thresholds $t = [10, 20, 30, 40]$, and the dataset values $dVal = [20, 30, 40, 50]$, so the predicate of $t_0 \leq dVal_0$ would result in taking the \texttt{true} branch, however this is also the case for $t_0 = 11$, making these two different settings, having the same dynamic behavior.